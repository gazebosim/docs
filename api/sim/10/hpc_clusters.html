<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=9"/>
    <meta name="keywords" content="Gazebo Sim">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Gazebo Sim: Gazebo on HPC clusters</title>
    <script type="text/javascript" src="https://gazebosim.org/assets/doxygen/dynsections.js"></script>
    <script type="text/javascript" src="jquery.js"></script>
    <link rel="icon" type="image/x-icon" href="https://gazebosim.org/assets/icon/favicon.ico">
    <link href='http://fonts.googleapis.com/css?family=Roboto:400,300,100,500,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.deep_orange-blue.min.css">
    <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>
    <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"> </script>
    <link href="https://gazebosim.org/assets/doxygen/doxygen.css" rel="stylesheet" type="text/css">
  </head>
    <script type="text/javascript">
      /* Replace all the "permalink" &#9670;&nbsp; icons with a unicode link
        symbol.*/
      $(document).ready(function() {
        var elems = document.getElementsByClassName("permalink");
        for (var i = 0; i < elems.length; ++i) {
          elems[i].firstChild.innerHTML="&#x1f517;";
          elems[i].firstChild.style.fontSize="18px";
        }
      });
    </script>
  </head>
<body>
  <div class="mdl-layout mdl-js-layout mdl-layout--fixed-drawer">
    <div class="mdl-layout__drawer mdl-color--grey-100 mdl-color-text--blue-grey-50">
      <header class="mdl-color--grey-100">
        <a href="index.html"><img width="60px" src="https://gazebosim.org/assets/doxygen/gazebo_logo.svg"/></a>
        <h1 class="project_title">Gazebo Sim</h1>
        <h2>API Reference</h2>
        <div class="version">
        10.0.0
        </div>
      </header>
      <!-- NOTE: If you add a link to a doxygen generated page, then make
                 sure to update the required_html_fils list in
                 GzCreateDocs.cmake -->
      <nav class="gz-navigation mdl-navigation">
        <a class="mdl-navigation__link" href="tutorials.html">
          <i class="mdl-color-text--grey-400 material-icons"
             role="presentation">insert_drive_file</i>Tutorials</a>
        <a id="class_menu" class="mdl-navigation__link" href="#">
          <i class="mdl-color-text--grey-400 material-icons"
             role="presentation">library_books</i>Classes</a>
        <a id="namespaces_menu"class="mdl-navigation__link" href="#">
          <i class="mdl-color-text--grey-400 material-icons"
             role="presentation">toc</i>Namespaces</a>
        <a class="mdl-navigation__link" href="files.html">
          <i class="mdl-color-text--grey-400 material-icons"
             role="presentation">insert_drive_file</i>Files</a>
        <a class="mdl-navigation__link" target="_blank"
           href="http://gazebosim.org">
          <i class="mdl-color-text--grey-400 material-icons"
             role="presentation">launch</i>Gazebo Website</a>
      </nav>
      <!-- classes sub menu -->
      <ul for="class_menu" class="mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect mdl-navigation">
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link" href="classes.html">Index</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
            href="annotated.html">List</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
             href="hierarchy.html">Hierarchy</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
             href="functions.html">Members: All</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
             href="functions_func.html">Members: Functions</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
             href="functions_vars.html">Members: Variables</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
             href="functions_type.html">Members: Typedefs</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
             href="functions_enum.html">Members: Enumerations</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
             href="functions_eval.html">Members: Enumerator</a>
        </li>
      </ul>
      <!-- namespaces sub menu -->
      <ul for="namespaces_menu" class="mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect mdl-navigation">
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
            href="namespaces.html">List</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
            href="namespacemembers.html">Members</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
            href="namespacemembers_func.html">Functions</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
            href="namespacemembers_type.html">Typedefs</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
            href="namespacemembers_vars.html">Variables</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
            href="namespacemembers_enum.html">Enumerations</a>
        </li>
        <li class="mdl-menu__item">
          <a class="mdl-navigation__link"
            href="namespacemembers_eval.html">Enumerator</a>
        </li>
      </ul>
    </div>
    <main class="mdl-layout__content mdl-color--white">
    <div id="top">
<!-- Generated by Doxygen 1.9.8 -->
</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">Gazebo on HPC clusters</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2><a class="anchor" id="overview-6"></a>
Overview</h2>
<p>This tutorial should help debugging and resolving the following problem: <b>I run Gazebo via Apptainer/Singularity on an HPC cluster and adding rendering sensors like cameras leads to a crash or they do not work (provide no or black output).</b></p>
<h2><a class="anchor" id="prerequisites-2"></a>
Prerequisites</h2>
<p>You have a Singularity/Apptainer image with Gazebo (and possibly ROS 2). Let's call it <code>image.sif</code>.</p>
<p>You work on an HPC (High-performance Computing) cluster such as university or national HPC centers. These clusters usually do not support Docker for security reasons and support Singularity/Apptainer instead. Some ideas from this answer may be applicable to Docker, too, but it is not a goal of this answer to provide support for Docker users.</p>
<p>Apptainer == Singularity for this tutorial. There are minor differences between reasonably new versions of these frameworks - but these are not important here (Singularity at least version 3.x, Apptainer any version). Since Apptainer installs command <code>singularity</code> for backwards compatibility, we'll be using <code>singularity</code> command here, but Apptainer users can substitute it for <code>apptainer</code> if they want.</p>
<p>Your HPC cluster has nodes with GPUs and you have access to them. These GPUs are capable of rendering. The author of this tutorial is not sure if the specialized "AI accelerators" like AMD MI300X and similar are capable of rendering at all. But the normal NVidia datacenter cards like A100, B200, V100 and similar are okay. Check the GPU type with <code>nvidia-smi</code> command run on a GPU node.</p>
<p>The HPC cluster runs some kind of task allocator that can give you time-limited access to some node with requested resources. The tutorial author's cluster uses SLURM, so we'll use SLURM commands here (<code>salloc</code>, <code>srun</code> etc.). But theoretically, this guide should be independent from the task allocation engine. For debugging purposes, it is better if the cluster provides interactive sessions. But even if it only supports batch sessions, this should be doable, it would just take more time to debug via batch jobs.</p>
<p>Let's assume the cluster partition with GPUs and interactive access is called <code>gpufast</code> and the partition with non-interactive GPU access is <code>gpu</code>.</p>
<p>We also assume the home directory of your user is shared between the cluster login node and the compute nodes. I.e. all files in your home folder are accessible both from the login node and from within allocated tasks running on nodes.</p>
<p>Your Gazebo world may be using either <code>ogre</code> or <code>ogre2</code> render engines, but <code>ogre2</code> provides more options, so it is suggested to use that. It should be configured <a href="https://github.com/gazebosim/gz-sim/blob/f67671cb3c6b309f14a04209edb94dc3fdc53b65/examples/worlds/sensors_demo.sdf#L15-L19">in the Sensors system</a>. You can also pass <code>--render-engine ogre2</code> on the Gazebo command line to override the value specified in the world file.</p>
<p>Gazebo can render using 2 backends on Linux: <b>GLX</b> or <b>EGL</b>. GLX is the older one, supported by both <code>ogre</code> and <code>ogre2</code> render engines. GLX needs a running X11 server and it uses its GPU to do the rendering. Running a HW-accelerated X11 server yourself is a bit nontrivial, but doable, as we'll show later. EGL is the newer backend and it is only supported by <code>ogre2</code> render engine and only for server-side rendering (i.e. it cannot be used for GUI). EGL is selected by the <code>--headless-rendering</code> flag of Gazebo server. EGL works with devices <code>/dev/dri/card?</code> and <code>/dev/dri/renderD???</code>. Each pair of these files belongs to one GPU. Gazebo uses an autoselection algorithm to choose which GPU will be used (it takes the first one capable of creating an EGL context). This guide shows how the GPU can be selected explicitly.</p>
<p>To use EGL, you need read-write access to both <code>/dev/dri/card?</code> and <code>/dev/dri/renderD???</code> devices. To check that, run the following command:</p>
<div class="fragment"><div class="line">user@cluster$ srun -p gpufast--gres=gpu:1 --pty bash -i</div>
<div class="line">user@gpu-node-1$ for f in /dev/dri/*; do [ -r &quot;$f&quot; ] &amp;&amp; [ -w &quot;$f&quot; ] &amp;&amp; echo &quot;OK  $f&quot; || echo &quot;NOK $f&quot;; done</div>
</div><!-- fragment --><p>Even if you see some NOKs, you can try following this guide. SLURM uses some other magic to allow access (cgroups).</p>
<dl class="section note"><dt>Note</dt><dd>All the following approaches use <code>gz sim -s</code> command to test the rendering. It might be easier for you to test it with <code>glxgears</code> instead, which is a simple binary that should just show rotating cog wheels rendered by the GPU. This will work with all further described approaches, except approach 3 (<code>--headless-rendering</code>). To use <code>glxgears</code>, you need to install package <code>mesa-utils</code> (on Debian-based systems) or <code>glx-utils</code> (on Fedora-based systems) inside your image. Then, instead of <code>gz sim -v4 -r -s sensors_demo.sdf</code>, type <code>glxgears -info | cut -c -80</code> and look at the value of <code>GL_RENDERER</code>. <code>llvmpipe</code> is software rendering (slow), anything else should be GPU-accelerated.</dd>
<dd>
The approaches are ordered by the simplicity of their use/setup if they work. However, most HPC clusters will probably not support Approach 1 and 2, so you can also start with Approach 3 first and then go to 1 and 2 if it doesn't work.</dd></dl>
<h2><a class="anchor" id="approach-1-initial-test"></a>
Approach 1: Initial test</h2>
<dl class="section note"><dt>Note</dt><dd><b>Do not try to run GUI on the cluster unless the server-only part works</b>. It would only complicate things. To run only Gazebo server, make sure flag <code>-s</code> is in the <code>gz sim</code> command line (and <code>-g</code> is not).</dd></dl>
<p><em>This tests Gazebo in GLX mode connected to an existing X server.</em></p>
<p>Try directly running Gazebo on the GPU node. For easier testing and to rule-out ROS complexity, use the <code>sensors_demo.sdf</code> world that comes preinstalled with Gazebo. If you don't have it, just <a href="https://github.com/gazebosim/gz-sim/blob/gz-sim10/examples/worlds/sensors_demo.sdf">download it</a> e.g. to your home folder and provide an absolute path to the file instead of simply <code>sensors_demo.sdf</code>.</p>
<div class="fragment"><div class="line">user@cluster$ srun -p gpufast--gres=gpu:1 --pty bash -i</div>
<div class="line">user@gpu-node-1$ singularity exec image.sif bash -c &quot;echo $DISPLAY; gz sim -v4 -s -r sensors_demo.sdf &amp; (gz topic -t /camera -e | cut -c -80) &amp; sleep 30; kill %1; kill %2; sleep 2; kill -9 %1; kill -9 %2&quot;</div>
</div><!-- fragment --><p>This tests Gazebo on the interactive GPU partition. Now, let's do the same test on a noninteractive one. Prepare the following job spec into file <code>test.batch</code>:</p>
<div class="fragment"><div class="line">#!/bin/sh</div>
<div class="line">#SBATCH --time=1 -p gpu --gres=gpu:1</div>
<div class="line">singularity exec image.sif bash -c &quot;gz sim -v4 -s -r sensors_demo.sdf &amp; (gz topic -t /camera -e | cut -c -80) &amp; sleep 30; kill %1; kill %2; sleep 2; kill -9 %1; kill -9 %2&quot;</div>
</div><!-- fragment --><p>Of course, replace <code>-p gpu</code> with the name of your non-interactive GPU partition.</p>
<p>Schedule the batch for execution and wait until it is executed. Check <code>test.stdout</code> file for the output.</p>
<div class="fragment"><div class="line">user@cluster$ sbatch -n1 -o test.stdout test.batch</div>
<div class="line">user@cluster$ tail -F test.stdout</div>
</div><!-- fragment --><p>If the commands did not fail, did not print anything red and you see camera messages printed out, rendering is working for you. Now it's time to find out if it is HW-accelerated:</p>
<div class="fragment"><div class="line">user@cluster$ grep -C2 RENDERER ~/.gz/rendering/ogre2.log</div>
</div><!-- fragment --><p>If you see <code>llvmpipe</code> in the output, the rendering is not HW-accelerated and you should keep following this guide (unless you're happy with slower rendering). If the output contains <code>NVidia</code> (or <code>AMD</code>), tadaa, you have a working HW-accelerated rendering.</p>
<p>But usually, you'll see some kind of error like:</p>
<div class="fragment"><div class="line">[Err] [Ogre2RenderEngine.cc:342] Unable to open display:</div>
<div class="line">terminate called after throwing an instance of &#39;Ogre::RenderingAPIException&#39;</div>
<div class="line">  what():  OGRE EXCEPTION(3:RenderingAPIException): Couldn&#39;t open X display  in GLXGLSupport::getGLDisplay at /var/lib/jenkins/workspace/ogre-2.1-debbuilder/repo/RenderSystems/GL3Plus/src/windowing/GLX/OgreGLXGLSupport.cpp (line 789)</div>
</div><!-- fragment --><p><b>Explanation why this worked:</b> The cluster probably starts an X server for each GPU node allocation and gives you access to this X server (via <code>$DISPLAY</code> variable). Not many clusters do this. Some do it e.g. only for the interactive partitions (like the OP's one) so the first set of commands works, but the latter does not.</p>
<h2><a class="anchor" id="approach-2-add---nv-switch"></a>
Approach 2: Add --nv switch</h2>
<p><em>This tests Gazebo in GLX mode connected to an existing X server, passing &ndash;nv to Singularity.</em></p>
<p>Now it's time to get a bit further and try running Singularity with the <code>--nv</code> switch which basically adds some GPU-related host libraries to the container. If you're on AMD GPUs, you should use <code>--rocm</code> instead, but that is not tested. Contributions are welcome!</p>
<p>Test with almost the same command, just add <code>--nv</code> to singularity command:</p>
<div class="fragment"><div class="line">user@cluster$ srun -p gpufast--gres=gpu:1 --pty bash -i</div>
<div class="line">user@gpu-node-1$ singularity exec --nv image.sif bash -c &quot;echo $DISPLAY; gz sim -v4 -s -r sensors_demo.sdf &amp; (gz topic -t /camera -e | cut -c -80) &amp; sleep 30; kill %1; kill %2; sleep 2; kill -9 %1; kill -9 %2&quot;</div>
</div><!-- fragment --><p>Also, try it on the non-interactive partition, adjusting <code>test.batch</code> appropriately.</p>
<p>What can happen if the node's OS is much newer than the OS inside your image, is you'll get errors with GLIBC version mismatch. See <a href="https://github.com/apptainer/apptainer/issues/945#issuecomment-2096052536">https://github.com/apptainer/apptainer/issues/945#issuecomment-2096052536</a> for a workaround if that's your case.</p>
<p>If both interactive and non-interactive commands work for you in this case, you are done (again, verify <code>RENDERER</code> in <code>ogre2.log</code>).</p>
<p><b>Explanation why this worked:</b> Most Singularity images do not install proprietary NVidia drivers inside. Instead, they rely on the host drivers, and the <code>--nv</code> switch bind-mounts all files related to the host drivers inside the container. So if there is a running X11 server, the programs from container can use it.</p>
<h2><a class="anchor" id="approach-3-try---headless-rendering"></a>
Approach 3: Try --headless-rendering</h2>
<p><em>This tests Gazebo in EGL mode using autodetected GPU, passing &ndash;nv to Singularity.</em></p>
<p>This is the mode described in tutorial <a class="el" href="headless_rendering.html">Headless Rendering</a>.</p>
<p>If GLX does not work, let's try EGL backend:</p>
<div class="fragment"><div class="line">user@cluster$ srun -p gpufast --gres=gpu:1 --pty bash -i</div>
<div class="line">user@gpu-node-1$ singularity exec --nv image.sif bash -c &quot;gz sim -v4 -s -r --headless-rendering sensors_demo.sdf &amp; (gz topic -t /camera -e | cut -c -80) &amp; sleep 30; kill %1; kill %2; sleep 2; kill -9 %1; kill -9 %2&quot;</div>
</div><!-- fragment --><p>And, again, try the same on a non-interactive partition.</p>
<p>Check <code>RENDERER</code> in <code>ogre2.log</code> again.</p>
<p>You can also have a more detailed look into <code>~/.gz/rendering/ogre2.log</code>. It contains two parts. In the first part, Gazebo is probing the available GLX and EGL rendering devices. Here you can see whether Gazebo correctly detects your GPU. You can ignore the GLX errors as we've verified GLX doesn't work. Also, some EGL devices might occur multiple times, e.g. in this example <code>/dev/dri/card2</code> appears as <code>EGL_NV_device_cuda</code> and <code>EGL_EXT_device_drm</code>. It is okay if just one of the two "views" of the device work.</p>
<div class="fragment"><div class="line">01:13:59: OpenGL 3+ Rendering Subsystem created.</div>
<div class="line">01:13:59: OGRE EXCEPTION(3:RenderingAPIException): Couldn&#39;t open X display  in GLXGLSupport::getGLDisplay at ./.obj-x86_64-linux-gnu/gz_ogre_next_vendor-prefix/src/gz_ogre_next_vendor/RenderSystems/GL3Plus/src/windowing/GLX/OgreGLXGLSupport.cpp (line 808)</div>
<div class="line">01:13:59: GLX raised an exception. Won&#39;t be available. Is X11 running?</div>
<div class="line">01:13:59: OGRE EXCEPTION(3:RenderingAPIException): Couldn&#39;t open X display  in GLXGLSupport::getGLDisplay at ./.obj-x86_64-linux-gnu/gz_ogre_next_vendor-prefix/src/gz_ogre_next_vendor/RenderSystems/GL3Plus/src/windowing/GLX/OgreGLXGLSupport.cpp (line 808)</div>
<div class="line">01:13:59: Found Num EGL Devices: 5</div>
<div class="line">01:13:59: EGL Device: EGL_NV_device_cuda EGL_EXT_device_drm EGL_EXT_device_drm_render_node EGL_EXT_device_query_name EGL_EXT_device_persistent_id #0 /dev/dri/card2</div>
<div class="line">01:13:59: Trying to init device: EGL_NV_device_cuda EGL_EXT_device_drm EGL_EXT_device_drm_render_node EGL_EXT_device_query_name EGL_EXT_device_persistent_id #0 /dev/dri/card2...</div>
<div class="line">01:13:59: Created GL 4.5 context for device EGL_NV_device_cuda EGL_EXT_device_drm EGL_EXT_device_drm_render_node EGL_EXT_device_query_name EGL_EXT_device_persistent_id #0 /dev/dri/card2</div>
<div class="line">01:13:59: Destroying device: EGL_NV_device_cuda EGL_EXT_device_drm EGL_EXT_device_drm_render_node EGL_EXT_device_query_name EGL_EXT_device_persistent_id #0 /dev/dri/card2...</div>
<div class="line">01:13:59: EGL Device: EGL_NV_device_cuda EGL_EXT_device_drm EGL_EXT_device_drm_render_node EGL_EXT_device_query_name EGL_EXT_device_persistent_id #1 /dev/dri/card3</div>
<div class="line">01:13:59: Trying to init device: EGL_NV_device_cuda EGL_EXT_device_drm EGL_EXT_device_drm_render_node EGL_EXT_device_query_name EGL_EXT_device_persistent_id #1 /dev/dri/card3...</div>
<div class="line">01:13:59: Created GL 4.5 context for device EGL_NV_device_cuda EGL_EXT_device_drm EGL_EXT_device_drm_render_node EGL_EXT_device_query_name EGL_EXT_device_persistent_id #1 /dev/dri/card3</div>
<div class="line">01:13:59: Destroying device: EGL_NV_device_cuda EGL_EXT_device_drm EGL_EXT_device_drm_render_node EGL_EXT_device_query_name EGL_EXT_device_persistent_id #1 /dev/dri/card3...</div>
<div class="line">01:13:59: EGL Device: EGL_EXT_device_drm EGL_EXT_device_drm_render_node #2 /dev/dri/card2</div>
<div class="line">01:13:59: Trying to init device: EGL_EXT_device_drm EGL_EXT_device_drm_render_node #2 /dev/dri/card2...</div>
<div class="line">01:13:59: OGRE EXCEPTION(3:RenderingAPIException): eglInitialize failed for device EGL_EXT_device_drm EGL_EXT_device_drm_render_node #2 /dev/dri/card2 in EGLSupport::getGLDisplay at ./.obj-x86_64-linux-gnu/gz_ogre_next_vendor-prefix/src/gz_ogre_next_vendor/RenderSystems/GL3Plus/src/windowing/EGL/PBuffer/OgreEglPBufferSupport.cpp (line 320)</div>
<div class="line">01:13:59: OGRE EXCEPTION(3:RenderingAPIException): eglInitialize failed for device EGL_EXT_device_drm EGL_EXT_device_drm_render_node #2 /dev/dri/card2 in EGLSupport::getGLDisplay at ./.obj-x86_64-linux-gnu/gz_ogre_next_vendor-prefix/src/gz_ogre_next_vendor/RenderSystems/GL3Plus/src/windowing/EGL/PBuffer/OgreEglPBufferSupport.cpp (line 320)</div>
<div class="line">01:13:59: Destroying device: EGL_EXT_device_drm EGL_EXT_device_drm_render_node #2 /dev/dri/card2...</div>
<div class="line">01:13:59: EGL Device: EGL_EXT_device_drm EGL_EXT_device_drm_render_node #3 /dev/dri/card3</div>
<div class="line">01:13:59: Trying to init device: EGL_EXT_device_drm EGL_EXT_device_drm_render_node #3 /dev/dri/card3...</div>
<div class="line">01:13:59: OGRE EXCEPTION(3:RenderingAPIException): eglInitialize failed for device EGL_EXT_device_drm EGL_EXT_device_drm_render_node #3 /dev/dri/card3 in EGLSupport::getGLDisplay at ./.obj-x86_64-linux-gnu/gz_ogre_next_vendor-prefix/src/gz_ogre_next_vendor/RenderSystems/GL3Plus/src/windowing/EGL/PBuffer/OgreEglPBufferSupport.cpp (line 320)</div>
<div class="line">01:13:59: OGRE EXCEPTION(3:RenderingAPIException): eglInitialize failed for device EGL_EXT_device_drm EGL_EXT_device_drm_render_node #3 /dev/dri/card3 in EGLSupport::getGLDisplay at ./.obj-x86_64-linux-gnu/gz_ogre_next_vendor-prefix/src/gz_ogre_next_vendor/RenderSystems/GL3Plus/src/windowing/EGL/PBuffer/OgreEglPBufferSupport.cpp (line 320)</div>
<div class="line">01:13:59: Destroying device: EGL_EXT_device_drm EGL_EXT_device_drm_render_node #3 /dev/dri/card3...</div>
<div class="line">01:13:59: EGL Device: EGL_MESA_device_software EGL_EXT_device_drm_render_node #4</div>
<div class="line">01:13:59: Trying to init device: EGL_MESA_device_software EGL_EXT_device_drm_render_node #4...</div>
<div class="line">01:13:59: Created GL 4.5 context for device EGL_MESA_device_software EGL_EXT_device_drm_render_node #4</div>
<div class="line">01:13:59: Destroying device: EGL_MESA_device_software EGL_EXT_device_drm_render_node #4...</div>
<div class="line">01:13:59: Plugin successfully installed</div>
</div><!-- fragment --><p>In the second part, you should see <code>Starting EGL Subsystem</code>. This confirms Gazebo uses the EGL backend. Right beneath this line, you should see which device is used for rendering:</p>
<div class="fragment"><div class="line">01:13:59: ******************************</div>
<div class="line">*** Starting EGL Subsystem ***</div>
<div class="line">******************************</div>
<div class="line">01:13:59: GL3PlusRenderSystem::_createRenderWindow &quot;OgreWindow(0)_0&quot;, 1x1 windowed  miscParams: FSAA=0 border=none contentScalingFactor=1.000000 gamma=Yes parentWindowHandle=0 stereoMode=Frame Sequential</div>
<div class="line">01:13:59: Trying to init device: EGL_NV_device_cuda EGL_EXT_device_drm EGL_EXT_device_drm_render_node EGL_EXT_device_query_name EGL_EXT_device_persistent_id #0 /dev/dri/card2...</div>
<div class="line">01:13:59: Created GL 4.5 context for device EGL_NV_device_cuda EGL_EXT_device_drm EGL_EXT_device_drm_render_node EGL_EXT_device_query_name EGL_EXT_device_persistent_id #0 /dev/dri/card2</div>
<div class="line">01:13:59: GL Version = 4.5.0.0</div>
<div class="line">01:13:59: GL_VERSION = 4.5.0 NVIDIA 550.120</div>
<div class="line">01:13:59: GL_VENDOR = NVIDIA Corporation</div>
<div class="line">01:13:59: GL_RENDERER = NVIDIA GeForce RTX 3090/PCIe/SSE2</div>
</div><!-- fragment --><p>If you see <code>EGL_MESA_device_software</code> or <code>llvmpipe</code> in this part, it means EGL works, but is not HW-accelerated. Look in the first section with probing to find out what problems are preventing to use a HW device.</p>
<p><b>Explanation why this worked:</b> <code>--headless-rendering</code> switches Gazebo to the EGL backend.</p>
<h2><a class="anchor" id="approach-4-use-virtualgl-and-a-dummy-x-server"></a>
Approach 4: Use VirtualGL and a dummy X server</h2>
<p><em>This tests Gazebo in GLX mode using a selected GPU, connected to a dummy X server.</em></p>
<p>Generally, one of the 3 above approaches should work for you if your cluster allows rendering at all. However, some GPUs have problems with some ways of rendering, while working fine when done differently. Also, this allows you to explicitly select the GPU to be used. Last, this method can be used to run even Gazebo GUI on the cluster (if you e.g. want to record the GUI camera programmatically).</p>
<p>First, you will need VirtualGL inside your image. Download a .deb or .rpm from <a href="https://github.com/VirtualGL/virtualgl/releases">https://github.com/VirtualGL/virtualgl/releases</a> and <code>sudo apt install name_of.deb</code> or <code>sudo rpm -i name_of.deb</code>. You will also need an X server. You can install <code>Xvfb</code> (<code>sudo apt install xvfb</code>), which only provides the rendering backbone, but the actual rendered on-screen images are thrown away (sensor rendering happens in off-screen buffers, so sensors are not affected). Or you can install TurboVNC (from <a href="https://github.com/TurboVNC/turbovnc/releases">https://github.com/TurboVNC/turbovnc/releases</a>), which is an X server that provides a VNC interface to which you can connect with any remote desktop client. Also install <code>mesa-utils</code>/<code>glx-utils</code> if you haven't yet.</p>
<p>Rebuild the image and you should be able to run this command:</p>
<div class="fragment"><div class="line">user@cluster$ srun -p gpufast--gres=gpu:1 --pty bash -i</div>
<div class="line">user@gpu-node-1$ singularity exec image.sif xvfb-run -a glxgears -info | cut -c -80</div>
</div><!-- fragment --><p>This does not yet mean Gazebo HW-accelerated rendering works, because this only tests software (non-accelerated) rendering.</p>
<p>Now you have to figure out which of the <code>/dev/dri/card?</code> EGL devices is the card allocated to you by the cluster. The easiest thing is just trial and error (you can use any of the card devices for which the command does not fail):</p>
<div class="fragment"><div class="line">user@cluster$ srun -p gpufast--gres=gpu:1 --pty bash -i</div>
<div class="line">user@gpu-node-1$ singularity exec --nv image.sif bash -c &#39;for f in /dev/dri/card*; do vglrun +v -d &quot;$f&quot; xvfb-run -a glxgears -info | cut -c -80; done&#39;</div>
</div><!-- fragment --><p>Of course, there are more sophisticated methods. Here is an example Bash script that translates IDs of the cards as shown by nvidia-smi to the <code>card?</code> and <code>renderD???</code> devices:</p>
<div class="fragment"><div class="line">#!/bin/bash -e</div>
<div class="line"> </div>
<div class="line">NVIDIA_SMI_ID=${1:-0}</div>
<div class="line"> </div>
<div class="line">minor=$(nvidia-smi -q -x -i $NVIDIA_SMI_ID 2&gt;/dev/null | grep minor | cut -d &gt; -f2 | cut -d &lt; -f1)</div>
<div class="line">if [ -z &quot;$minor&quot; ]; then</div>
<div class="line">  echo &quot;NVIDIA_SMI_ID=${NVIDIA_SMI_ID} does not denote an accessible GPU. Please, pass one of the IDs displayed by nvidia-smi.&quot; &gt;&amp;2</div>
<div class="line">  exit 1</div>
<div class="line">fi</div>
<div class="line"> </div>
<div class="line">echo &quot;NVIDIA_SMI_ID=${NVIDIA_SMI_ID}&quot;</div>
<div class="line">pci_id=$(nvidia-smi -i $NVIDIA_SMI_ID --query-gpu=pci.bus_id --format=noheader,csv | tail -c+5 | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;)</div>
<div class="line"> </div>
<div class="line">nvidia=/dev/nvidia$minor</div>
<div class="line">card=$(ls /sys/bus/pci/devices/${pci_id}/drm/ | grep card)</div>
<div class="line">render=$(ls /sys/bus/pci/devices/${pci_id}/drm/ | grep renderD)</div>
<div class="line"> </div>
<div class="line">echo &quot;NVIDIA_DEVICE=$nvidia&quot;</div>
<div class="line">echo &quot;DRI_DEVICE=$card&quot;</div>
<div class="line">echo &quot;RENDER_NODE=$render&quot;</div>
</div><!-- fragment --><p>If you find a working card (let's call it <code>cardN</code>), you can run Gazebo (do not logout from the GPU node, otherwise the number of the card can change!) :</p>
<div class="fragment"><div class="line"># on the same GPU node where you determined the available card</div>
<div class="line">user@gpu-node-1$ singularity exec --nv image.sif bash -c &quot;vglrun +v -d /dev/dri/cardN xvfb-run -a gz sim -v4 -s -r sensors_demo.sdf &amp; (gz topic -t /camera -e | cut -c -80) &amp; sleep 30; kill %1; kill %2; sleep 2; kill -9 %1; kill -9 %2&quot;</div>
</div><!-- fragment --><p>Testing on the non-interactive partition looks the same, but you have to figure out the available card device automatically, e.g. using the Bash script above.</p>
<p>If you want to actually see the graphical output (if running Gazebo with GUI), use TurboVNC instead of Xvfb (it will print the VNC port at the start):</p>
<div class="fragment"><div class="line"># on the same GPU node where you determined the available card</div>
<div class="line">user@gpu-node-1$ singularity exec --nv image.sif /opt/TurboVNC/bin/vncserver -fg -log /dev/stdout -xstartup &quot;vglrun +v -d /dev/dri/cardN gz sim -v4 -r sensors_demo.sdf &amp; (gz topic -t /camera -e | cut -c -80) &amp; sleep 30; kill %1; kill %2; sleep 2; kill -9 %1; kill -9 %2&quot;</div>
</div><!-- fragment --><p>This, of course, assumes you have direct network access to the cluster nodes and any ports you open on them.</p>
<p>Again, verify that Gazebo outputs no red text and check <code>RENDERER</code> in <code>ogre2.log</code>.</p>
<p><b>Explanation why this worked:</b> VirtualGL redirects GLX calls to a specified EGL device (using some very low-level tricks). However, the app (Gazebo) still thinks it's using GLX, so it needs an X server. That's the place for <code>xvfb</code> or <code>TurboVNC</code>.</p>
<h2><a class="anchor" id="approach-5---nv-is-broken-but-there-is-hope"></a>
Approach 5: --nv is broken, but there is hope</h2>
<p>On some systems, the <code>--nv</code> switch does not add all files necessary for working with VirtualGL inside a container. You can try to fix that and bind-mount these manually. This should help with approaches 2, 3 and 4.</p>
<p>Someone had to mount these in addition to the default:</p>
<div class="fragment"><div class="line">--bind /usr/lib64/libEGL_nvidia.so.0 --bind /usr/share/glvnd/egl_vendor.d/</div>
</div><!-- fragment --><p>It seems that Apptainer 1.4.0 and newer <a href="https://github.com/apptainer/apptainer/pull/2572">should already have this fixed</a>. But if you have an older version, these manual binds will do the job.</p>
<p>It is possible that your system has other files that will need to be mounted. You can try to search for them manually around the files that are mentioned in <code>/etc/singularity/nvliblist.conf</code>. Or, if your cluster provides <code>nvidia-container-cli</code> command, you can try to extract the list of files from <code>nvidia-container-cli list</code>. But the author of the tutorial does not have access to a cluster with this command, so this is untested (there is even <code>--nvccli</code> flag in addition to <code>--nv</code> in Apptainer that could help with this).</p>
<h3><a class="anchor" id="low-level-last-resort-only-for-adventurous-or-desperate"></a>
Low-Level Last Resort (only for adventurous or desperate)</h3>
<p>Alternatively, you can utilize <code>strace</code> and try running VirtualGL directly on the GPU node outside Singularity container. However, this approach is quite complicated for many users.</p>
<p>If you can get <code>strace</code> working directly on the GPU node (not inside Singularity), you can also unpack packages <code>mesa-utils</code>/<code>glx-utils</code>, <code>xvfb</code> and <code>VirtualGL</code> to some of your writable locations and try to run them directly on the node. This will rule-out problems introduced by Singularity.</p>
<p>First, download .deb or .rpm files of the packages for the version of OS that is running on the GPU node (use <code>cat /etc/*-release</code> to figure it out). To unpack a .deb file, run <code>dpkg-deb -xv file.deb .</code> . To unpack an .rpm file, run <code>rpm2cpio file.rpm | cpio -idmv</code> or <code>rpm2cpio file.rpm | zstd -d | cpio -idmv</code> .</p>
<p>Next, add the unpacked lib and lib64 folders to <code>LD_LIBRARY_PATH</code> and bin folders to <code>PATH</code>. Then you can use <code>strace</code>, <code>xvfb</code>, <code>virtualgl</code> and <code>glxgears</code> to test which NVidia files are loaded:</p>
<div class="fragment"><div class="line">LD_LIBRARY_PATH=&quot;`pwd`/usr/lib64:$LD_LIBRARY_PATH&quot; PATH=&quot;`pwd`/usr/bin:$PATH&quot; strace -f -e openat ./opt/VirtualGL/bin/vglrun +v -d /dev/dri/card1 xvfb-run -a glxgears -info 2&gt;&amp;1 | grep -v ENOENT | grep -i nv</div>
</div><!-- fragment --><p>The command may fail for various reasons, you might need to download recursive dependencies and so on. If your cluster uses e.g. the Lmod modules system, you can provide a part of the dependencies just by typing <code>module load X11</code>. If you can get this working, you would get the definitive answer to which files are needed inside the container. If not, you just have to guess. </p>
<p><b>Explanation why this worked:</b> The list of files in <code>nvliblist.conf</code> is just a guess. Some might be missing, some <a href="https://github.com/apptainer/apptainer/issues/945#issuecomment-1374524681">are there and shouldn't</a>. If you finish this list manually by adding <code>--bind</code> mounts of the missing files, you will have a working GLX and EGL system inside the container.</p>
<h2><a class="anchor" id="if-nothing-works"></a>
If Nothing Works</h2>
<p>If nothing from the above works, it is possible that your cluster has just not configured the GPU resources properly and it doesn't give you the permissions to use the GPUs via the <code>/dev/dri/</code> files, but only through <code>/dev/nvidia?</code>.</p>
<p>You can try contacting your cluster admins and showing them this link with a suggestion how to reconfigure the resources: <a href="https://groups.google.com/g/slurm-users/c/n_oUtvdTC4o/m/r4abS8KMBAAJ">https://groups.google.com/g/slurm-users/c/n_oUtvdTC4o/m/r4abS8KMBAAJ</a> . At the time of writing that post, there was no folder <code>/dev/dri/by-path</code>. On recent machines, this folder is present, so it could be even easier to define the resources. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
      </div>
    </main>
  </div>
</body>
